{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CHALLENGE: Non Performing Loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this data challenge! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework\n",
    "\n",
    "A non-performing loan (**NPL**) is the sum of borrowed money upon which the debtor has not made his scheduled payments for at least 90 days. Once a loan is non-performing, the odds that it will be fully repaid are considered to be substantially lower. High levels of NPLs inhibit the capacity of banks to lend to the economy and take up valuable bank management time. As of the third quarter of 2016, NPLs of significant institutions in the Euro area amounted to â‚¬921bln (average NPE of 7%), therefore the ECB asks banks to devise a strategy to manage and reduce the volume of impaired loans. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Objective\n",
    "\n",
    "The general goal of this data challenge is to help NPL portfolios managers in their daily tasks by re-ranking their customers according to the likelihood to repay and/or by suggesting new strategies to **maximize the recovery rate**. In particular, you are asked to perform analysis on the given data, train predictive models and present your findings in a clear and data-driven way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "You should have reiceived different CSVs along with this README Jupyter Notebook. These files contain synthetic but very realistic data on NPL counterperties. In particular, you should have: \n",
    "\n",
    "\n",
    "| FILE NAME  | BRIEF DESCRIPTION |\n",
    "| ------------- | ------------- |\n",
    "| ANAGRAFICA_CLIENTI.csv  | customers' registry data |\n",
    "| CC.csv | bank accounts data |\n",
    "| CENTRALE_RISCHI.csv | central risk data |\n",
    "| GARANZIE.csv | guarantees data |\n",
    "| MUTUI.csv | mortgage data |\n",
    "| PERIMETRO_INIZIALE.csv | customers in scope |\n",
    "| TRANSCODIFICA_GARANZIE.csv | decoding table for guarantees |\n",
    "| DICTIONARY.xlsx | detailed explaination of columns |\n",
    "\n",
    "The last file contains a detailed description for every column of each CSV listed above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable \n",
    "\n",
    "No target variable is given because in a real world setting it should be created according to business requirements and project objectives. Therefore, you will be asked to create the target variable by motivating your choices in a coherent way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Advices\n",
    "\n",
    "Please, keep in mind the advices below during your analysis. \n",
    "\n",
    "* Manage carefully your time to deliver a high quality analysis that answers most of the required tasks. \n",
    "* Make questions and give reasonable answers in a data-driven way. \n",
    "* Pay attention to details without losing focus on the general objective of this challenge. \n",
    "* Keep track of your assumptions and motivate them during the discussion. \n",
    "* Model performance is important but not the most important.\n",
    "* Knowing how to run model.fit() doesn't make you automatically a data scientist. :) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enjoy the challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform all your analysis in __Python__ or __R__. Present your findings in a clean and coherent way, for example, by using **Jupyter Notebook** or **R Markdown**. The code that you deliver along with the presentation should be well-organized and appropriately commented so that it is ready to be re-run to reproduce any of your results, also on a new dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required tasks\n",
    "\n",
    "This list contains the minimum required tasks you should complete (not necessarily in this order). However, we strongly encourage any your additional observation useful to achieve the challenge objective. \n",
    "\n",
    "### 1. Data Exploration\n",
    "Perform some data explorations on the given CSVs, point out your interesting findings and answer the questions below. \n",
    " * How are they connected? Which are the columns you should use to join them? \n",
    " * Focus on a single daset: CC.csv\n",
    "     * How many months of data do you have?  \n",
    "     * Are there seasonalities over the time? If yes, in which (aggregated) variables? Make some plots. \n",
    "     * Are there correlations between columns? \n",
    " \n",
    "### 2. Data Cleaning \n",
    "Select at least two datasets\n",
    " * Detect weird values, outliers and missing values. \n",
    "     * Which techniques or algorithms do you use to detect them?\n",
    "     * How do you treat them? Is it ok to remove them from the dataset? \n",
    "     * Is there any evident inconsistency in the data? If yes, how would you clean the data to overcome it? \n",
    " * Why did you select these datasets?\n",
    " \n",
    "### 3. Target Variable\n",
    "As in the real world, you are asked to create the target variable for this challenge by keeping in mind the challenge objective stated above. \n",
    " * Create a data matrix to feed models (you can decide to use only a subset of the given datasets).\n",
    " * Which granularity did you select and why?\n",
    " * Which columns identify each occurence?\n",
    " * Propose a target variable construction, write it with a mathematics formula and implement it. \n",
    " * Explain and validate every choice/assumption you made in the previous point, also with business intuitions. \n",
    " * If you decide to not have a target variable to predict, explain carefully your decision and how this could influence next steps in this analysis.  \n",
    "\n",
    "### 4. Features Engineering\n",
    "Given or not the target variable defined above, you can choose the features to use in a predictive model. \n",
    " * Create new features (we suggest ~3) from existing columns. Explain the intuition behind them.\n",
    " * Select a subset of features to use to train a predictive model. The selection process should be rigorous and reproducible. \n",
    "\n",
    "### 5. Modeling and Performance\n",
    "This is the fancy part, right? \n",
    " * How would you split the dataset to have train, test and validation set? \n",
    " * Which models have you tried to fit? Explain them.\n",
    " * Which metrics have you used to measure the performance? Why?\n",
    " * What have you done to improve models' performance? Are they useful? \n",
    "\n",
    "### 6. Presentation of the results\n",
    "Along with the Jupyter Notebook or the R Markdown, prepare a concise Power Point presentation where the steps 1-5 are explained to a non-technical audience and a proposal of future development is made. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2019-05-20 00:54:13.015023\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Last update: \" + str(datetime.datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}